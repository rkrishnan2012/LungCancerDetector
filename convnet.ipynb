{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import dicom\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import traceback\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "\n",
    "from multiprocessing.dummy import Pool as ThreadPool \n",
    "from tqdm import tqdm\n",
    "from skimage import measure, morphology\n",
    "from skimage.draw import polygon\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from tempfile import TemporaryFile\n",
    "\n",
    "# Get a list of patient folders in the data folder.\n",
    "INPUT_FOLDER = 'example_dcm/'\n",
    "patients = os.walk('./example_dcm').next()[1]\n",
    "patients.sort()\n",
    "\n",
    "test_patients = os.walk('./provisional_dcm_no_gt').next()[1]\n",
    "test_patients.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "IMG_SIZE_PX = 50\n",
    "SLICE_COUNT = 20\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "\n",
    "\n",
    "n_classes = 6\n",
    "\n",
    "x = tf.placeholder('float')\n",
    "y = tf.placeholder('float')\n",
    "\n",
    "keep_rate = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_bounding_cube(cancer, resize_factor):\n",
    "    a = np.where(cancer != 0)\n",
    "    coords = np.min(a[0]), np.max(a[0]), np.min(a[1]), np.max(a[1]), np.min(a[2]), np.max(a[2])\n",
    "    box = [coords[0] * resize_factor[0], coords[2] * resize_factor[1], coords[4] * resize_factor[2], (coords[1] - coords[0]) * resize_factor[0], (coords[3] - coords[2]) * resize_factor[1], (coords[5] - coords[4]) * resize_factor[2]]\n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load the CT and RT documents for a patient.\n",
    "def load_scan(path):\n",
    "    def listdir_nohidden(path):\n",
    "        for f in os.listdir(path):\n",
    "            if not f.startswith('.'):\n",
    "                yield f\n",
    "    slice_rt = [dicom.read_file(path + \"/RTst/\" + s) for s in listdir_nohidden(path + \"/RTst\")]\n",
    "    slice_ct = [dicom.read_file(path + \"/CT/\" + s) for s in listdir_nohidden(path + \"/CT\")]\n",
    "    slice_ct.sort(key = lambda x: int(x.ImagePositionPatient[2]))    \n",
    "    return slice_ct, slice_rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_image_patient(patient):\n",
    "    if os.path.exists(INPUT_FOLDER + patient + \"/50x50x20.npy\"):\n",
    "        if os.path.exists(INPUT_FOLDER + patient + \"/50x50x20_cancer.npy\"):\n",
    "            resized_image = np.load(INPUT_FOLDER + patient + \"/50x50x20.npy\");\n",
    "            cancer_cube = np.load(INPUT_FOLDER + patient + \"/50x50x20_cancer.npy\");\n",
    "            return resized_image, cancer_cube / 50;\n",
    "        \n",
    "    image = np.load(INPUT_FOLDER + patient + \"/image.npy\");\n",
    "    cancer = np.load(INPUT_FOLDER + patient + \"/truthV1.npy\");\n",
    "    resize_factor = [float(IMG_SIZE_PX) / image.shape[0], float(IMG_SIZE_PX) / image.shape[1], float(SLICE_COUNT) / image.shape[2]]\n",
    "    resized_image = scipy.ndimage.interpolation.zoom(image, resize_factor, mode='nearest');\n",
    "    cancer_cube = get_bounding_cube(cancer, 1 / image.shape);\n",
    "    np.save(INPUT_FOLDER + patient + \"/50x50x20.npy\", resized_image);\n",
    "    np.save(INPUT_FOLDER + patient + \"/50x50x20_cancer.npy\", cancer_cube);\n",
    "    \n",
    "    # Uncomment to show image of patient CT somewhere in the middle\n",
    "    # plt.imshow(resized_image.transpose()[30])\n",
    "    # plt.show()\n",
    "            \n",
    "    return resized_image, cancer_cube "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf9fc6a2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a,b = get_image_patient(patients[0])\n",
    "plt.imshow(a.transpose()[10])\n",
    "plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv3d(x, W):\n",
    "    return tf.nn.conv3d(x, W, strides=[1,1,1,1,1], padding='SAME')\n",
    "\n",
    "def maxpool3d(x):\n",
    "    #                        size of window         movement of window as you slide about\n",
    "    return tf.nn.max_pool3d(x, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding='SAME')\n",
    "def fc(x, weight, bias):\n",
    "    shape = x.get_shape().as_list()\n",
    "    dim = 1\n",
    "    for d in shape[1:]:\n",
    "        if d is not None:\n",
    "            dim *= d\n",
    "    x = tf.reshape(x, [-1, dim])\n",
    "    return tf.matmul(x, weight) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv_2(x):\n",
    "               # 3 x 3 x 3 patches, 1 channel, 32 features to compute.\n",
    "    weights = {'W_conv1':tf.Variable(tf.random_normal([3, 3, 3, 1, 32])),\n",
    "               # 3 x 3 x 3 patches, 32 channels, 64 features to compute.\n",
    "               'W_conv2':tf.Variable(tf.random_normal([3, 3, 3, 32, 64])),\n",
    "               # 52 because 50 plus zero padding on each border\n",
    "               'W_fc':tf.Variable(tf.random_normal([(IMG_SIZE_PX + 2) * (IMG_SIZE_PX + 2) * SLICE_COUNT, 1024])),\n",
    "               'out':tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "    biases = { 'b_conv1':tf.Variable(tf.random_normal([32])),\n",
    "               'b_conv2':tf.Variable(tf.random_normal([64])),\n",
    "               'b_fc':tf.Variable(tf.random_normal([1024])),\n",
    "               'out':tf.Variable(tf.random_normal([n_classes], 0, 0.1))}\n",
    "\n",
    "    #                            image X      image Y        image Z\n",
    "    x = tf.reshape(x, shape=[-1, IMG_SIZE_PX, IMG_SIZE_PX, SLICE_COUNT, 1])\n",
    "\n",
    "    conv1 = tf.nn.relu(conv3d(x, weights['W_conv1']) + biases['b_conv1'])\n",
    "    conv1 = maxpool3d(conv1)\n",
    "\n",
    "\n",
    "    conv2 = tf.nn.relu(conv3d(conv1, weights['W_conv2']) + biases['b_conv2'])\n",
    "    conv2 = maxpool3d(conv2)\n",
    "\n",
    "    fc = tf.reshape(conv2,[-1, (IMG_SIZE_PX + 2) * (IMG_SIZE_PX + 2) * SLICE_COUNT])\n",
    "    fc = tf.nn.relu(tf.matmul(fc, weights['W_fc']) + biases['b_fc'])\n",
    "    fc = tf.nn.dropout(fc, keep_rate)\n",
    "\n",
    "    output = tf.matmul(fc, weights['out']) + biases['out']\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def vgg_16(x):\n",
    "    weights = {'conv1_1':tf.Variable(tf.random_normal([3, 3, 3, 1, 64])),\n",
    "               'conv1_2':tf.Variable(tf.random_normal([3, 3, 3, 64, 64])),\n",
    "               'conv2_1':tf.Variable(tf.random_normal([3, 3, 3, 64, 128])),\n",
    "               'conv2_2':tf.Variable(tf.random_normal([3, 3, 3, 128, 128])),\n",
    "               'conv3_1':tf.Variable(tf.random_normal([3, 3, 3, 128, 256])),\n",
    "               'conv3_2':tf.Variable(tf.random_normal([3, 3, 3, 256, 256])),\n",
    "               'conv3_3':tf.Variable(tf.random_normal([3, 3, 3, 256, 256])),\n",
    "               'conv4_1':tf.Variable(tf.random_normal([3, 3, 3, 256, 512])),\n",
    "               'conv4_2':tf.Variable(tf.random_normal([3, 3, 3, 512, 512])),\n",
    "               'conv4_3':tf.Variable(tf.random_normal([3, 3, 3, 512, 512])),\n",
    "               'conv5_1':tf.Variable(tf.random_normal([3, 3, 3, 512, 512])),\n",
    "               'conv5_2':tf.Variable(tf.random_normal([3, 3, 3, 512, 512])),\n",
    "               'conv5_3':tf.Variable(tf.random_normal([3, 3, 3, 512, 512])),\n",
    "               'fc6':tf.Variable(tf.random_normal([2048, 2048])),\n",
    "               'fc7':tf.Variable(tf.random_normal([2048, 1024])),               \n",
    "               'out':tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "    biases = { 'b_conv1_1':tf.Variable(tf.random_normal([64])),\n",
    "               'b_conv1_2':tf.Variable(tf.random_normal([64])),\n",
    "               'b_conv2_1':tf.Variable(tf.random_normal([64])),\n",
    "               'b_conv2_2':tf.Variable(tf.random_normal([128])),\n",
    "               'b_conv3_1':tf.Variable(tf.random_normal([256])),\n",
    "               'b_conv3_2':tf.Variable(tf.random_normal([256])),\n",
    "               'b_conv3_3':tf.Variable(tf.random_normal([256])),\n",
    "               'b_conv4_1':tf.Variable(tf.random_normal([512])),\n",
    "               'b_conv4_2':tf.Variable(tf.random_normal([512])),\n",
    "               'b_conv4_3':tf.Variable(tf.random_normal([512])),\n",
    "               'b_conv5_1':tf.Variable(tf.random_normal([512])),\n",
    "               'b_conv5_2':tf.Variable(tf.random_normal([512])),\n",
    "               'b_conv5_3':tf.Variable(tf.random_normal([512])),\n",
    "               'b_fc6':tf.Variable(tf.random_normal([2048])),\n",
    "               'b_fc7':tf.Variable(tf.random_normal([1024])),               \n",
    "               'out':tf.Variable(tf.random_normal([n_classes], 0, 0.1))}\n",
    "    \n",
    "     #                            image X      image Y        image Z\n",
    "    x = tf.reshape(x, shape=[-1, IMG_SIZE_PX, IMG_SIZE_PX, SLICE_COUNT, 1])\n",
    "    \n",
    "    conv1_1 = tf.nn.relu(conv3d(x, weights['conv1_1']) + biases['b_conv1_1'])\n",
    "    conv1_2 = tf.nn.relu(conv3d(conv1_1, weights['conv1_2']) + biases['b_conv1_2'])\n",
    "    pool1 = maxpool3d(conv1_2)\n",
    "    \n",
    "    conv2_1 = tf.nn.relu(conv3d(pool1, weights['conv2_1']) + biases['b_conv2_1'])\n",
    "    conv2_2 = tf.nn.relu(conv3d(conv2_1, weights['conv2_2']) + biases['b_conv2_2'])\n",
    "    pool2 = maxpool3d(conv2_1)\n",
    "    \n",
    "    conv3_1 = tf.nn.relu(conv3d(pool2, weights['conv3_1']) + biases['b_conv3_1'])\n",
    "    conv3_2 = tf.nn.relu(conv3d(conv3_1, weights['conv3_2']) + biases['b_conv3_2'])\n",
    "    conv3_3 = tf.nn.relu(conv3d(conv3_2, weights['conv3_3']) + biases['b_conv3_3'])\n",
    "    pool3 = maxpool3d(conv3_3)\n",
    "    \n",
    "    conv4_1 = tf.nn.relu(conv3d(pool3, weights['conv4_1']) + biases['b_conv4_1'])\n",
    "    conv4_2 = tf.nn.relu(conv3d(conv4_1, weights['conv4_2']) + biases['b_conv4_2'])\n",
    "    conv4_3 = tf.nn.relu(conv3d(conv4_2, weights['conv4_3']) + biases['b_conv4_3'])\n",
    "    pool4 = maxpool3d(conv4_3)\n",
    "    \n",
    "    conv5_1 = tf.nn.relu(conv3d(pool4, weights['conv5_1']) + biases['b_conv5_1'])\n",
    "    conv5_2 = tf.nn.relu(conv3d(conv5_1, weights['conv5_2']) + biases['b_conv5_2'])\n",
    "    conv5_3 = tf.nn.relu(conv3d(conv5_2, weights['conv5_3']) + biases['b_conv5_3'])\n",
    "    pool5 = maxpool3d(conv5_3)\n",
    "    \n",
    "    fc6 = tf.nn.relu(fc(pool5, weights['fc6'], biases['b_fc6']))\n",
    "    fc6 = tf.nn.dropout(fc6, keep_rate)\n",
    "    \n",
    "    fc7 = tf.nn.relu(fc(fc6, weights['fc7'], biases['b_fc7']))\n",
    "    fc7 = tf.nn.dropout(fc7, keep_rate)\n",
    "    \n",
    "    output = tf.matmul(fc7, weights['out']) + biases['out']\n",
    "    \n",
    "    return output;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pre_process_all_images(patients):\n",
    "    for i in patients:\n",
    "        print \"Resizing patient \", i\n",
    "        resized_image, cube = get_image_patient(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_neural_network(x):\n",
    "    prediction = conv_2(x)\n",
    "    cost = tf.reduce_sum(tf.pow(prediction - y, 2))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\n",
    "    \n",
    "    tf.add_to_collection('optimizer', optimizer)\n",
    "    tf.add_to_collection('cost', cost)\n",
    "    \n",
    "    lastSaveTime = time.time()\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    ckpt_num = 1;\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        if os.path.exists(\"model-19.meta\"):\n",
    "            saver = tf.train.import_meta_graph('./model-19.meta')\n",
    "            saver.restore(sess, './model-19')\n",
    "            optimizer = tf.get_collection('optimizer')[0]\n",
    "            cost = tf.get_collection('cost')[0]\n",
    "            print(\"Model restored.\")\n",
    "            loss = tf.reduce_sum(tf.pow(prediction - y, 2))\n",
    "            print('TestSetLoss:',loss.eval({x:[get_image_patient(i)[0] for i in patients[-50:]], y:[get_image_patient(i)[1] for i in patients[-50:]]}))\n",
    "            \n",
    "        \n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            epoch_loss = 0\n",
    "            currTime = time.time()\n",
    "                \n",
    "            for i in patients[:-50]:\n",
    "                resized_image, cube = get_image_patient(i)\n",
    "                \n",
    "                _, c = sess.run([optimizer, cost], feed_dict={x: resized_image, y: cube})\n",
    "                epoch_loss += c                \n",
    "                \n",
    "            print('Epoch', epoch+1, 'completed out of',NUM_EPOCHS,'loss:',epoch_loss)\n",
    "            a,b = get_image_patient(patients[1])\n",
    "            print sess.run(prediction, feed_dict={x:a})\n",
    "\n",
    "            \n",
    "            if(currTime - lastSaveTime > 60*30):\n",
    "                loss = tf.reduce_sum(tf.pow(prediction - y, 2))\n",
    "                print('TestSetLoss:',loss.eval({x:[get_image_patient(i)[0] for i in patients[-50:]], y:[get_image_patient(i)[1] for i in patients[-50:]]}))\n",
    "                lastSaveTime = currTime\n",
    "                a,b = get_image_patient(patients[1])\n",
    "                print sess.run(prediction, feed_dict={x:a})\n",
    "                save_path = saver.save(sess, \"model\", ckpt_num)\n",
    "                ckpt_num +=1;\n",
    "                print(\"Model saved in file: %s\" % save_path)\n",
    "        \n",
    "#                 a,b = get_image_patient(patients[0])\n",
    "#                 sess.run(prediction, feed_dict={x:a})\n",
    "#             \n",
    "#             print('Loss:',loss.eval({x:[get_image_patient(i)[0] for i in patients[50:60]], y:[get_image_patient(i)[1] for i in patients[50:60]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "('TestSetLoss:', 4.614729e+14)\n",
      "('Epoch', 1, 'completed out of', 1, 'loss:', 7.2694306750781834)\n",
      "[[ 0.39529282  0.44529739  0.22401525  0.09126683  0.09195869  0.04262531]]\n"
     ]
    }
   ],
   "source": [
    "# pre_process_all_images(patients)\n",
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda env tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
